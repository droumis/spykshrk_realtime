{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet of code properly adds the working source root path to python's path\n",
    "# so you no longer have to install spykshrk through setuptools\n",
    "import sys, os\n",
    "root_depth = 2\n",
    "notebook_dir = globals()['_dh'][0]\n",
    "root_path = os.path.abspath(os.path.join(notebook_dir, '../'*root_depth))\n",
    "# Add to python's path\n",
    "try:\n",
    "    while True:\n",
    "        sys.path.remove(root_path)\n",
    "except ValueError:\n",
    "    # no more root paths\n",
    "    pass\n",
    "sys.path.append(root_path)\n",
    "# Alternatively set root path as current working directory\n",
    "#os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import functools\n",
    "import holoviews as hv\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPEncoder, OfflinePPDecoder\n",
    "from spykshrk.franklab.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                              LinearPosition, StimLockout, Posteriors\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer, DecodeErrorVisualizer\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 120)\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoviews import Store\n",
    "from bokeh.models.arrow_heads import TeeHead\n",
    "Store.add_style_opts(hv.ErrorBars, ['upper_head', 'lower_head'], backend='bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv_300samp/bond.config.json'\n",
    "#config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/test/test.config.json'\n",
    "\n",
    "\n",
    "config = json.load(open(config_file, 'r'))\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "\n",
    "# Main hdf5 data source file name\n",
    "hdf_file = os.path.join(config['files']['output_dir'],\n",
    "                        '{}.rec_merged.h5'.format(config['files']['prefix']))\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Open data file\n",
    "store = pd.HDFStore(hdf_file, mode='r')\n",
    "\n",
    "# Encapsulate Spike Observation panda table in container\n",
    "observ_obj = SpikeObservation.from_realtime(store['rec_3'], day=day, epoch=epoch, enc_settings=encode_settings)\n",
    "\n",
    "# Grab stimulation lockout times\n",
    "stim_lockout = StimLockout.from_realtime(store['rec_11'], enc_settings=encode_settings)\n",
    "\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "linflat_obj = lin_obj.get_mapped_single_axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%prun -r\n",
    "# Run PP decoding algorithm\n",
    "\n",
    "time_bin_size = 300\n",
    "\n",
    "decoder = OfflinePPDecoder(observ_obj=observ_obj, trans_mat=OfflinePPEncoder.calc_uniform_trans_mat(encode_settings),\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_est_pos = posteriors.get_distribution_view().idxmax(axis=1).apply(lambda x: int(x[1:])).to_frame()\n",
    "dec_est_pos.columns = ['est_pos']\n",
    "\n",
    "resamp_lin_obj = lin_obj.get_resampled(time_bin_size).get_pd_no_multiindex()\n",
    "\n",
    "dec_error = LinearDecodeError()\n",
    "\n",
    "dec_error = dec_error.calc_error_table(resamp_lin_obj, dec_est_pos,\n",
    "                                       encode_settings.arm_coordinates, 2)\n",
    "\n",
    "print(\"Median:\")\n",
    "print(dec_error.loc[:, idx[:, 'abs_error']].median())\n",
    "print(\"Mean:\")\n",
    "print(dec_error.loc[:, idx[:, 'abs_error']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts ErrorBars {+framewise} [height=500 width=1000] (line_color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']) line_width=1 upper_head=TeeHead(size=0) lower_head=TeeHead(size=0))\n",
    "%%opts Points {+framewise} [height=500 width=1000] (color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']))\n",
    "%%output holomap='scrubber'\n",
    "\n",
    "#warnings.filterwarnings(action='')\n",
    "\n",
    "dec_viz = DecodeErrorVisualizer(dec_error)\n",
    "\n",
    "dmap = dec_viz.plot_arms_error_dmap(20,50)\n",
    "\n",
    "dmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}