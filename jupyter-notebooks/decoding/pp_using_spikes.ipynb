{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This snippet of code properly adds the working source root path to python's path\n",
    "# so you no longer have to install spykshrk through setuptools\n",
    "import sys, os\n",
    "root_depth = 2\n",
    "notebook_dir = globals()['_dh'][0]\n",
    "root_path = os.path.abspath(os.path.join(notebook_dir, '../'*root_depth))\n",
    "# Add to python's path\n",
    "try:\n",
    "    while True:\n",
    "        sys.path.remove(root_path)\n",
    "except ValueError:\n",
    "    # no more root paths\n",
    "    pass\n",
    "sys.path.append(root_path)\n",
    "# Alternatively set root path as current working directory\n",
    "#os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import json\n",
    "import os\n",
    "import scipy.signal\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import aggregate, shade, datashade, dynspread, regrid\n",
    "from holoviews.operation import decimate\n",
    "\n",
    "from spykshrk.realtime.simulator import nspike_data\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.util import gaussian, normal2D, apply_no_anim_boundary, simplify_pos_pandas\n",
    "from spykshrk.franklab.pp_decoder.pp_clusterless import OfflinePPEncoder, OfflinePPDecoder\n",
    "from spykshrk.franklab.data_containers import EncodeSettings, DecodeSettings, SpikeObservation, \\\n",
    "                                              LinearPosition, StimLockout, Posteriors, \\\n",
    "                                              FlatLinearPosition, pos_col_format\n",
    "\n",
    "from spykshrk.franklab.pp_decoder.visualization import DecodeVisualizer, DecodeErrorVisualizer\n",
    "from spykshrk.franklab.pp_decoder.decode_error import LinearDecodeError\n",
    "\n",
    "        \n",
    "%load_ext Cython\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#pd.set_option('float_format', '{:,.2f}'.format)\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "#pd.set_option('display.width', 80)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "#matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.extension('bokeh')\n",
    "hv.Store.renderers['bokeh'].webgl = False\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 14})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from holoviews import Store\n",
    "from bokeh.models.arrow_heads import TeeHead\n",
    "Store.add_style_opts(hv.ErrorBars, ['upper_head', 'lower_head'], backend='bokeh')\n",
    "Store.add_style_opts(hv.ErrorBars, ['ecolor'], backend='matplotlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "except:\n",
    "    print(\"No cluster or client\")\n",
    "    \n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=20, threads_per_worker=2,)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load merged rec HDF store based on config\n",
    "\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/ripple_dec/bond.config.json'\n",
    "#config_file = '/opt/data36/daliu/realtime/spykshrk/dec_60uv/bond.config.json'\n",
    "config_file = '/home/daliu/Src/spykshrk_realtime/config/bond_single.json'\n",
    "config = json.load(open(config_file, 'r'))\n",
    "\n",
    "day = config['simulator']['nspike_animal_info']['days'][0]\n",
    "epoch = config['simulator']['nspike_animal_info']['epochs'][0]\n",
    "time_bin_size = config['pp_decoder']['bin_size']\n",
    "\n",
    "# Main hdf5 data source file name\n",
    "hdf_file = os.path.join(config['files']['output_dir'],\n",
    "                        '{}.rec_merged.h5'.format(config['files']['prefix']))\n",
    "\n",
    "# Extract just encode and decode settings from config\n",
    "encode_settings = EncodeSettings(config)\n",
    "decode_settings = DecodeSettings(config)\n",
    "\n",
    "# Open data file\n",
    "store = pd.HDFStore(hdf_file, mode='r')\n",
    "\n",
    "# Encapsulate Spike Observation panda table in container\n",
    "observ_obj = SpikeObservation.from_realtime(store['rec_3'], day=day, epoch=epoch, enc_settings=encode_settings)\n",
    "\n",
    "# Grab stimulation lockout times\n",
    "stim_lockout = StimLockout.from_realtime(store['rec_11'], enc_settings=encode_settings)\n",
    "\n",
    "# Grab animal linearized real position\n",
    "nspike_anim = nspike_data.AnimalInfo(**config['simulator']['nspike_animal_info'])\n",
    "pos = nspike_data.PosMatDataStream(nspike_anim)\n",
    "pos_data = pos.data\n",
    "\n",
    "# Encapsulate linear position\n",
    "lin_obj = LinearPosition.from_nspike_posmat(pos_data, encode_settings)\n",
    "\n",
    "ripcons = nspike_data.RipplesConsData(nspike_anim)\n",
    "ripdata = ripcons.data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%prun -r -s cumulative\n",
    "\n",
    "# Run PP decoding algorithm\n",
    "time_bin_size = 30\n",
    "\n",
    "decoder = OfflinePPDecoder(observ_obj=observ_obj, trans_mat=OfflinePPEncoder.calc_uniform_trans_mat(encode_settings),\n",
    "                           encode_settings=encode_settings, decode_settings=decode_settings, \n",
    "                           time_bin_size=time_bin_size)\n",
    "\n",
    "posteriors = decoder.run_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts RGB { +framewise} [height=100 width=250 colorbar=True]\n",
    "%%opts Points {+framewise} [height=100 width=250] (marker='o' size=4 alpha=0.5)\n",
    "%%opts Polygons (color='grey', alpha=0.5 fill_color='grey' fill_alpha=0.3)\n",
    "\n",
    "dec_viz = DecodeVisualizer(posteriors, linpos=lin_obj, enc_settings=encode_settings, riptimes=ripdata)\n",
    "\n",
    "dec_viz.plot_all_dynamic(stream=hv.streams.RangeXY(), plt_range=10, slide=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Image {+axiswise} [height=300 width=300 aspect=1]\n",
    "%%opts Curve.arm_bound {+axiswise} [aspect=1] (line_dash='dashed' color='#AAAAAA' linestyle='--' alpha=0.5)\n",
    "%%opts Points {+axiswise} [aspect=1] (marker='*' size=14)\n",
    "%%opts NdLayout {+axiswise}\n",
    "%%output backend='matplotlib' size=200\n",
    "\n",
    "dec_viz = DecodeVisualizer(posteriors, linpos=lin_obj, riptimes=ripdata.get_above_maxthresh(5), enc_settings=encode_settings)\n",
    "\n",
    "rip_plots = dec_viz.plot_ripple_grid(2)\n",
    "for plt_grp in rip_plots:\n",
    "    display(plt_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dec_est_pos = posteriors.get_distribution_view().idxmax(axis=1).apply(lambda x: int(x[1:])).to_frame()\n",
    "dec_est_pos.columns = ['est_pos']\n",
    "dec_est_pos['linvel_flat'] = dec_est_pos['est_pos'].diff()/np.insert(np.diff(dec_est_pos.index.get_level_values('time')), 0, 0)\n",
    "\n",
    "dec_est_pos = FlatLinearPosition.create_default(dec_est_pos, encode_settings.sampling_rate,\n",
    "                                                encode_settings.arm_coordinates, parent=posteriors)\n",
    "\n",
    "resamp_lin_obj = lin_obj.get_resampled(time_bin_size).get_pd_no_multiindex()\n",
    "\n",
    "error_obj = LinearDecodeError()\n",
    "\n",
    "error_table = error_obj.calc_error_table(resamp_lin_obj, dec_est_pos,\n",
    "                                         encode_settings.arm_coordinates, 2)\n",
    "\n",
    "print(error_table.loc[:, idx[:, 'abs_error']].median())\n",
    "print(error_table.loc[:, idx[:, 'abs_error']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output backend='bokeh' size=400 holomap='scrubber'\n",
    "%%opts Points {+framewise} [height=100 width=250 aspect=2] (color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']))\n",
    "%%opts ErrorBars {+framewise} [height=100 width=250 aspect=2 ] (ecolor=Cycle(values=['#FF0099', '#99FF00', '#5555FF']) color=Cycle(values=['#FF0099', '#99FF00', '#5555FF']) alpha=0.5 line_width=1 upper_head=TeeHead(size=0) lower_head=TeeHead(size=0))\n",
    "\n",
    "err_viz = DecodeErrorVisualizer(error_table)\n",
    "\n",
    "dmap = err_viz.plot_arms_error_dmap(slide_interval=10, plot_interval=10)\n",
    "\n",
    "dmap"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}